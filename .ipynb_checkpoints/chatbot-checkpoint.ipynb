{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1242f-d40c-49d5-ad17-570c9076d1cb",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39573eb-30e4-461b-9294-1e33525af263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766db817-e698-44cf-b849-5cd352e51057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "#core deep learning framework\n",
    "from transformers import  AutoTokenizer\n",
    "from optimum.intel import OVModelForCausalLM ,OVModelForFeatureExtraction\n",
    "\n",
    "#prompt managme\n",
    "from faiss import IndexFlatL2\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "#utillty\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed08022-4db9-4ea1-b963-a950bdf4112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n",
      "Setting OpenVINO CACHE_DIR to quantized_model/INT_8/model_cache\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(join(\"quantized_model\",\"tokenizer\"))\n",
    "model = OVModelForCausalLM.from_pretrained(join(\"quantized_model\",\"INT_8\"))#,export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca835326-6eef-4c04-a1f4-dd0ac934b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfbc27e-c82e-4c4e-8341-c55816938031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export to ONNX.\n",
      "Using the export variant default. Available variants are:\n",
      "\t- default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.1.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "#u can use any feature extraction model here\n",
    "emb_tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-small\")\n",
    "emb_model = OVModelForFeatureExtraction.from_pretrained(\"thenlper/gte-small\",export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5616f-c77d-46a9-a86b-9b56048fbfff",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa631d8-dd82-411c-a2c2-123ee2b96059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_dict(d):\n",
    "    return {k:np.array(v).shape for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f628d9-d841-4df1-b07d-9587b0c7fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used almost everywhere for chatbot apis this is a good thing to know\n",
    "#I found myself writing this function in every chatbot I ever made\n",
    "def openai_format(text: str, role ='system'):\n",
    "    assert role in ('assistant','user','system')\n",
    "    return {'content':text,'role':role}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb2b95-ffe7-4e1e-ad11-b773c966f2b0",
   "metadata": {},
   "source": [
    "# database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9255e3-e20f-4c27-aa01-52e7d745b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of product descriptions for the SereniTea chatbot\n",
    "product_descriptions = [\n",
    "    \"\"\"Matcha is a premium green tea powder from Japan. Once prepared, it becomes a vibrant green beverage with a creamy mouthfeel. Its unique flavor is rich and grassy with undertones of umami. Traditionally used in tea ceremonies, Matcha is also a popular ingredient in modern culinary dishes and beverages.\"\"\",\n",
    "    \n",
    "    \"\"\"Chamomile tea is a herbal infusion made from dried chamomile flowers and is renowned for its mild and soothing flavor that hints at a light apple sweetness. Widely consumed for its calming effects and its ability to improve sleep quality, Chamomile tea is a nighttime favorite.\"\"\",\n",
    "    \n",
    "    \"\"\"Oolong tea, a traditional Chinese tea, is made from leaves of the same plant that gives us green and black tea. Its oxidation process is stopped somewhere between the standards for green and black tea, giving it a complexity of flavor and aroma that can range from bright and floral to rich and savory.\"\"\",\n",
    "    \n",
    "    \"\"\"Black tea is known for its strong flavors and is the most oxidized of all tea types. It can range in flavor from sweet and malty to robust and smoky. Regular consumption of black tea has been linked to a variety of health benefits, including improved cholesterol levels and better gut health and immunity.\"\"\"\n",
    "    # Additional product descriptions would be appended to the list\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c68fac-d95c-4548-9a8c-12fc9eebfa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': (4, 79), 'attention_mask': (4, 79)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict = tokenizer(product_descriptions, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "shape_dict(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cbd33d-84e7-498a-9e3b-645f039ceb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/intel_chatbot/lib/python3.8/site-packages/optimum/intel/openvino/modeling_decoder.py:374: FutureWarning: `shared_memory` is deprecated and will be removed in 2024.0. Value of `shared_memory` is going to override `share_inputs` value. Please use only `share_inputs` explicitly.\n",
      "  self.request.start_async(inputs, shared_memory=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logits': (4, 79, 32000), 'past_key_values': (32, 2, 4, 32, 79, 128)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs=model(**batch_dict)\n",
    "shape_dict(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29416de6-bcfb-45d7-a14c-af038313cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 79, 4096)\n"
     ]
    }
   ],
   "source": [
    "def get_last_key(outputs):\n",
    "    #geting the last key\n",
    "    emb=np.array(outputs['past_key_values'])[-1][0] #shape = (Batch, 32, Time, 128)\n",
    "    #combining over attention heads\n",
    "    emb=emb.swapaxes(1,2) #shape = (Batch, Time, 32, 128) \n",
    "    return emb.reshape(emb.shape[:2]+(-1,)) #shape = (Batch, Time, 4096)\n",
    "\n",
    "emb=get_last_key(outputs)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e817e55f-ffac-4d88-a32b-677d0086e11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_pool(array, attention_mask):\n",
    "    return (array*attention_mask[:, :, np.newaxis]).sum(1)/attention_mask.sum(1)[:,np.newaxis]\n",
    "\n",
    "pool=average_pool(emb,batch_dict['attention_mask'].numpy())\n",
    "pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4652232f-5c57-413e-a225-c3cf85d549e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(outputs,inputs):\n",
    "    key=get_last_key(outputs)\n",
    "    return average_pool(key,inputs['attention_mask'].numpy())\n",
    "\n",
    "embeddings=get_embedding(outputs,batch_dict)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1a455-678c-42b9-b518-4044118234ac",
   "metadata": {},
   "source": [
    "## embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680e3cee-c2b9-4816-830c-a248c310bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states,attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def make_embedding(texts):\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = emb_tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    outputs = emb_model(**batch_dict)\n",
    "    #print(outputs.keys())\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b957d8cb-fe08-4433-8106-fc8583d46b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4337214 , -0.14420573,  0.3533751 , ..., -0.68104327,\n",
       "         0.6894532 , -0.17023948],\n",
       "       [-0.18854867, -0.04905184,  0.3122417 , ...,  0.08611374,\n",
       "         0.9116094 ,  0.01603312],\n",
       "       [ 0.05724301, -0.17354068,  0.3363754 , ..., -0.18687753,\n",
       "         0.90574044,  0.22618802],\n",
       "       [-0.11154529, -0.17711419,  0.12071578, ..., -0.43974218,\n",
       "         0.8788762 ,  0.20621175]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings=make_embedding(product_descriptions)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1928f-0e2a-4acf-9cf3-ab671adc07e2",
   "metadata": {},
   "source": [
    "## faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1345c03-d09f-4a19-b3b3-768d437eacab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7fea6d0bcc00> >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_index=IndexFlatL2(embeddings.shape[-1])\n",
    "database_index.add(embeddings)\n",
    "database_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c206004-e3d8-4561-8a71-5c2898ce9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[24.36969]], dtype=float32), array([[3]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb=make_embedding(['I am having stomach issues what tea is best for me?'])\n",
    "ans=database_index.search(emb,1)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d0af69-553b-4105-92bf-21ca849799a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Black tea is known for its strong flavors and is the most oxidized of all tea types. It can range in flavor from sweet and malty to robust and smoky. Regular consumption of black tea has been linked to a variety of health benefits, including improved cholesterol levels and better gut health and immunity.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_descriptions[ans[1][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e420cdf-c359-412c-a276-6a86881f05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oolong tea, a traditional Chinese tea, is made from leaves of the same plant that gives us green and black tea. Its oxidation process is stopped somewhere between the standards for green and black tea, giving it a complexity of flavor and aroma that can range from bright and floral to rich and savory.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_product(text):\n",
    "    emb=make_embedding([text])\n",
    "    ans=database_index.search(emb,1)\n",
    "    return product_descriptions[ans[1][0][0]]\n",
    "\n",
    "get_product('hey I want to add some tea to my dish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00977063-551c-4fc1-8dd3-eeb4ead3a298",
   "metadata": {},
   "source": [
    "# chatbot\n",
    "this is being debugged rn something is very off about it. \n",
    "seems like the model has a strong tendency to repeat the prompt\n",
    "and when we try and corect that by adding a no repeat we see it do small modifications to get away with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "322a72ea-c34e-4dd2-97bb-1a93473908f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'you are a sales chatbot in charge of the tea shop \\'Moms Homebrew Tea\\' help line.\\nyou will help users figure out which of our products fits them best. \\nbased on the curent conversation the system retrived this product:\\n\"Matcha is a premium green tea powder from Japan. Once prepared, it becomes a vibrant green beverage with a creamy mouthfeel. Its unique flavor is rich and grassy with undertones of umami. Traditionally used in tea ceremonies, Matcha is also a popular ingredient in modern culinary dishes and beverages.\"\\ntell the user about the parts that are relevent to them and explain that we make the tea in house by specialists.\\nif the user isnt happy with the tea. or if you think this product isnt the best fit try and get the user to be more specific',\n",
       " 'role': 'system'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_system_prompt(user_text):\n",
    "    product=get_product(user_text)\n",
    "    return openai_format(f'''\\\n",
    "you are a sales chatbot in charge of the tea shop 'Moms Homebrew Tea' help line.\n",
    "you will help users figure out which of our products fits them best. \n",
    "based on the curent conversation the system retrived this product:\n",
    "\"{product}\"\n",
    "tell the user about the parts that are relevent to them and explain that we make the tea in house by specialists.\n",
    "if the user isnt happy with the tea. or if you think this product isnt the best fit try and get the user to be more specific''')\n",
    "\n",
    "get_system_prompt('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c786fd6-24f3-4aa8-ae9d-53d47b8c7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(user_text):\n",
    "     return openai_format('say AAA to the user regardless of their message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd049c53-32c9-45cc-84ed-8b51a967e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['system', 'user']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n[INST] <<SYS>>\\nsay AAA to the user regardless of their messages\\n<</SYS>>\\n\\nhey I need some tea to help my stomach issues do you guys sell any? [/INST]\\n\\n[INST] <<SYS>>\\nsay BBB to the user regardless of their messages\\n<</SYS>>\\n\\nheyy I need some tea to help my stomach issues do you guys sell any [/INST]']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def respond_to_user(user_text,history):\n",
    "    #prompt enginerring\n",
    "    history.append(openai_format(user_text,'user'))\n",
    "    messages=(get_system_prompt(user_text),)+tuple(history)\n",
    "\n",
    "    print([x['role'] for x in messages])\n",
    "    #infrence\n",
    "    inputs=tokenizer.apply_chat_template(messages,return_tensors='pt',add_generation_prompt=True)\n",
    "    output=model.generate(inputs,max_new_tokens=100,min_new_tokens=2,no_repeat_ngram_size=17,num_beams=2,top_k=10,do_sample=True)\n",
    "    output=tokenizer.batch_decode(output[:,inputs.shape[-1]:],skip_special_tokens=True)\n",
    "    \n",
    "    #output\n",
    "    history.append(openai_format(output,'assistant'))\n",
    "    return output\n",
    "\n",
    "history=deque(maxlen=3)\n",
    "ans=respond_to_user('hey I need some tea to help with my stomach issues do you guys sell any?',history)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2ec8c9a-da71-4b8b-beca-5ed5a9a7e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([{'content': 'hey I need some tea to help with my stomach issues do you guys sell any?',\n",
       "        'role': 'user'},\n",
       "       {'content': ['[INST] <<SYS>>\\nsay AAA to the user regardless of their message\\n<</SYS>>\\n\\nhey I need some tea to help with my stomach issues do you guys sell any? [/INST]\\n\\n[INST] <<SYS>>\\nsay AAA to the user regardless of their messages\\n<</SYS>>\\n\\nhey I need some tea to help my stomach issues do you guys sell any? [/INST]\\n'],\n",
       "        'role': 'assistant'}],\n",
       "      maxlen=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e396ea1-fe7e-4f91-a8ef-887ba4946625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
